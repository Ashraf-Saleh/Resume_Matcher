{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Classification Project\n",
    "\n",
    "This project aims to classify resumes into various job categories using natural language processing (NLP) techniques and machine learning. The dataset used for training the model is sourced from [Kaggle's Updated Resume Dataset](https://www.kaggle.com/datasets/jillanisofttech/updated-resume-dataset).\n",
    "\n",
    "## Overview\n",
    "\n",
    "The process involves several key steps:\n",
    "1. **Data Loading:** The resume dataset is loaded into a DataFrame.\n",
    "2. **Text Preprocessing:** A cleaning function is applied to remove unnecessary characters, URLs, and stopwords from the resume text.\n",
    "3. **Feature Vectorization:** The cleaned text data is transformed into numerical feature vectors using `CountVectorizer`.\n",
    "4. **Label Encoding:** Job categories are encoded into numeric labels for model training.\n",
    "5. **Model Training:** A `MultinomialNB` classifier is trained using a One-vs-Rest approach. The Multinomial classifier is particularly suited for text classification tasks because it is effective in handling the discrete features commonly found in text data. The One-vs-Rest approach allows the model to treat each category as a separate binary classification problem, improving its ability to distinguish between multiple classes.\n",
    "6. **Model Evaluation:** The trained model's performance is evaluated using accuracy and classification metrics.\n",
    "7. **Prediction Function:** A function is defined to predict the category of new resumes, outputting match percentages for various job categories.\n",
    "\n",
    "This notebook will guide you through each step of the process, providing insights into the techniques used and the results obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset\n",
    "This cell imports the `pandas` library and loads the dataset from a CSV file named `UpdatedResumeDataSet.csv` into a DataFrame called `final_df`. This DataFrame will contain the resume data along with their respective job categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "final_df = pd.read_csv('data/UpdatedResumeDataSet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Additional Libraries and Download NLTK Stopwords\n",
    "This cell imports additional libraries required for text processing, including `re`, `string`, `nltk.corpus.stopwords`, `CountVectorizer`, and `LabelEncoder`. It also downloads the NLTK stopwords if they haven't been downloaded already. The `stop_words` variable is created as a set of English stopwords, which will be used to clean the resume text later.\n",
    "\n",
    "# Define the `clean_resume` Function\n",
    "This cell defines a function named `clean_resume` that takes a single input parameter:\n",
    "\n",
    "- **Input:**\n",
    "  - `resume_text` (str): The raw text of a resume that needs to be cleaned.\n",
    "\n",
    "- **Output:**\n",
    "  - Returns a cleaned string where:\n",
    "    - URLs, mentions, hashtags, and extra whitespace are removed.\n",
    "    - Punctuation and non-alphabet characters are eliminated.\n",
    "    - Stopwords and specific words (e.g., \"year,\" \"month\") are filtered out.\n",
    "  \n",
    "The cleaned text is returned as a single string, which will be used for further processing.\n",
    "\n",
    "# Apply the Cleaning Function\n",
    "This cell applies the `clean_resume` function to the 'Resume' column of the `final_df` DataFrame. The cleaned resume text replaces the original text in the DataFrame, ensuring that all resumes are preprocessed before they are vectorized.\n",
    "\n",
    "# Encode Labels\n",
    "This cell creates an instance of `LabelEncoder` and fits it to the 'Category' column of the `final_df` DataFrame. This transforms the categorical job categories into numeric labels, which will be used for training the machine learning model. The encoded categories replace the original categorical values in the DataFrame.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ashraf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you have your simplified dataset loaded as final_df with 'Category' and 'Resume' columns\n",
    "\n",
    "# Download stopwords if not already done\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Define a comprehensive function to clean resume text\n",
    "def clean_resume(resume_text):\n",
    "    # Remove URLs, RT, cc, hashtags, mentions, and extra whitespace\n",
    "    resume_text = re.sub('http\\S+\\s*', ' ', resume_text)\n",
    "    resume_text = re.sub('RT|cc', ' ', resume_text)\n",
    "    resume_text = re.sub('#\\S+', '', resume_text)\n",
    "    resume_text = re.sub('@\\S+', ' ', resume_text)\n",
    "    resume_text = re.sub(r'[^\\x00-\\x7f]', ' ', resume_text)\n",
    "    resume_text = re.sub('\\s+', ' ', resume_text)\n",
    "    \n",
    "    # Remove punctuation and non-alphabet characters\n",
    "    resume_text = re.sub('[%s]' % re.escape(string.punctuation), ' ', resume_text)\n",
    "    resume_text = re.sub(r'[^a-zA-Z\\s]', '', resume_text)\n",
    "\n",
    "    # Split into words and remove stop words, months, years\n",
    "    words = resume_text.split()\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words \n",
    "             and word.lower() not in [\"year\", \"years\", \"month\", \"months\"]\n",
    "             and not word.isdigit()]\n",
    "    \n",
    "    # Join cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function\n",
    "final_df['Resume'] = final_df['Resume'].apply(clean_resume)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "final_df['Category'] = label_encoder.fit_transform(final_df['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Text Data\n",
    "This cell creates an instance of `CountVectorizer`, which is then used to convert the cleaned resume text data into numerical feature vectors. The variable `X` contains the feature vectors, while `y` contains the corresponding numeric labels of the job categories. This transformation prepares the data for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(final_df['Resume'])\n",
    "y = final_df['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "This cell uses `train_test_split` to split the feature vectors (`X`) and the labels (`y`) into training and testing sets. The training set will be used to train the model, while the test set will be used to evaluate its performance. The `test_size` parameter is set to 0.2, indicating that 20% of the data will be used for testing, and stratification is applied to maintain the proportion of categories in both sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train the Model\n",
    "This cell defines a machine learning model using `MultinomialNB` in a One-vs-Rest configuration with `OneVsRestClassifier`. The model is then fitted to the training data (`X_train` and `y_train`). After fitting, predictions are made on the test set (`y_pred`), which will be used to evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9792746113989638\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      0.50      0.67         4\n",
      "                     Arts       0.88      1.00      0.93         7\n",
      "       Automation Testing       1.00      0.80      0.89         5\n",
      "               Blockchain       1.00      1.00      1.00         8\n",
      "         Business Analyst       0.86      1.00      0.92         6\n",
      "           Civil Engineer       1.00      1.00      1.00         5\n",
      "             Data Science       1.00      1.00      1.00         8\n",
      "                 Database       1.00      1.00      1.00         7\n",
      "          DevOps Engineer       1.00      0.91      0.95        11\n",
      "         DotNet Developer       1.00      1.00      1.00         5\n",
      "            ETL Developer       1.00      1.00      1.00         8\n",
      "   Electrical Engineering       0.86      1.00      0.92         6\n",
      "                       HR       1.00      1.00      1.00         9\n",
      "                   Hadoop       1.00      1.00      1.00         8\n",
      "       Health and fitness       1.00      1.00      1.00         6\n",
      "           Java Developer       1.00      1.00      1.00        17\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "Network Security Engineer       1.00      1.00      1.00         5\n",
      "       Operations Manager       1.00      1.00      1.00         8\n",
      "                      PMO       1.00      1.00      1.00         6\n",
      "         Python Developer       1.00      1.00      1.00        10\n",
      "            SAP Developer       1.00      1.00      1.00         5\n",
      "                    Sales       0.89      1.00      0.94         8\n",
      "                  Testing       1.00      1.00      1.00        14\n",
      "            Web Designing       1.00      1.00      1.00         9\n",
      "\n",
      "                 accuracy                           0.98       193\n",
      "                macro avg       0.98      0.97      0.97       193\n",
      "             weighted avg       0.98      0.98      0.98       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the model\n",
    "model = OneVsRestClassifier(MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions and Evaluate the Model\n",
    "This cell evaluates the trained model by calculating the accuracy score and generating a classification report, which includes precision, recall, and F1-score for each category. The results help assess how well the model is performing on the test set compared to the training data.\n",
    "\n",
    "# Define the `predication_func` Function\n",
    "This cell defines a function named `predication_func` that takes a single input parameter:\n",
    "\n",
    "- **Input:**\n",
    "  - `new_resume` (str): The raw text of a new resume that needs to be analyzed.\n",
    "\n",
    "- **Output:**\n",
    "  - The function prints the top match percentages for specified job categories and groups any remaining categories under \"Other.\"\n",
    "\n",
    "The function performs the following tasks:\n",
    "1. Cleans the new resume text using the `clean_resume` function.\n",
    "2. Vectorizes the cleaned resume using the same `CountVectorizer` used for the training data.\n",
    "3. Generates category probabilities using the trained model.\n",
    "4. Displays the match percentages for specified job categories in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the specific categories to display; others will be grouped under \"Other\"\n",
    "\n",
    "def predication_func(new_resume):\n",
    "\n",
    "    display_categories = [\n",
    "    \"Data Science\", \n",
    "    \"Database\", \n",
    "    \"DevOps Engineer\", \n",
    "    \"DotNet Developer\", \n",
    "    \"Java Developer\", \n",
    "    \"Python Developer\", \n",
    "    \"Testing\", \n",
    "    \"Web Designing\"\n",
    "    ]   \n",
    "    cleaned_resume = clean_resume(new_resume)\n",
    "\n",
    "    # Vectorize the cleaned resume using the same vectorizer\n",
    "    new_resume_vec = vectorizer.transform([cleaned_resume])\n",
    "\n",
    "    # Generate category probabilities\n",
    "    category_probs = model.predict_proba(new_resume_vec)\n",
    "\n",
    "    # Get category names instead of numeric labels\n",
    "    category_names = label_encoder.inverse_transform(model.classes_)\n",
    "\n",
    "    # Group the categories and calculate probabilities for \"Other\"\n",
    "    category_percentage = {}\n",
    "    other_total = 0  # To accumulate percentages for categories marked as \"Other\"\n",
    "\n",
    "    for i, prob in enumerate(category_probs[0]):\n",
    "        category_name = category_names[i]\n",
    "        if category_name in display_categories:\n",
    "            category_percentage[category_name] = prob * 100\n",
    "        else:\n",
    "            other_total += prob * 100\n",
    "\n",
    "    # Add \"Other\" category if there are remaining categories\n",
    "    if other_total > 0:\n",
    "        category_percentage[\"Other\"] = other_total\n",
    "\n",
    "    # # Display match percentages for each category\n",
    "    # print(\"Match percentages for each category:\")\n",
    "    # for category, percent in category_percentage.items():\n",
    "    #     print(f\"{category}: {percent:.2f}%\")\n",
    "\n",
    "    # Sort and display top matches\n",
    "    sorted_matches = sorted(category_percentage.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop category matches:\")\n",
    "    for category, percent in sorted_matches:\n",
    "        print(f\"{category}: {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resume_1 = \"\"\"\n",
    "Skills: Python, Django, Flask, REST APIs, SQL, NoSQL, Git, Docker, AWS, Data Analysis, Pandas, NumPy\n",
    "\n",
    "Experience:\n",
    "- Developed RESTful APIs using Django and Flask for an e-commerce platform, reducing load times by 20%.\n",
    "- Built automated scripts for data cleaning and ETL processes using Python and Pandas, saving 15 hours of manual work weekly.\n",
    "- Integrated third-party services with OAuth and JWT authentication for secure data handling.\n",
    "\n",
    "Education: Bachelor’s in Computer Science, University of California\n",
    "\n",
    "Projects:\n",
    "- Built a chatbot using Natural Language Processing techniques for customer support.\n",
    "- Developed a web scraping tool using Python and BeautifulSoup to extract and analyze online reviews.\n",
    "\"\"\"\n",
    "\n",
    "resume_2 = \"\"\"\n",
    "Skills: C#, .NET Core, ASP.NET MVC, Entity Framework, LINQ, SQL Server, Azure, Agile, Git, REST APIs\n",
    "\n",
    "Experience:\n",
    "- Designed and implemented web applications using ASP.NET MVC and .NET Core, increasing user engagement by 30%.\n",
    "- Worked with Azure DevOps to deploy and manage cloud-based applications.\n",
    "- Used Entity Framework to create and maintain database connections and ensure data integrity.\n",
    "\n",
    "Education: Bachelor’s in Information Technology, University of Texas\n",
    "\n",
    "Projects:\n",
    "- Developed a ticket booking system with ASP.NET Core and Entity Framework.\n",
    "- Created a performance monitoring tool for web apps to enhance response times by 25%.\n",
    "\"\"\"\n",
    "\n",
    "resume_3 = \"\"\"\n",
    "Skills: Java, Spring Boot, Hibernate, SQL, Microservices, Maven, Git, RESTful APIs, Jenkins, AWS\n",
    "\n",
    "Experience:\n",
    "- Built scalable microservices with Spring Boot, handling over 1 million requests per day.\n",
    "- Designed a notification system using Java and RabbitMQ, improving alert delivery efficiency by 40%.\n",
    "- Collaborated with cross-functional teams on Java-based applications for e-commerce platforms.\n",
    "\n",
    "Education: Bachelor’s in Software Engineering, University of Michigan\n",
    "\n",
    "Projects:\n",
    "- Developed a library management system using Java and Hibernate.\n",
    "- Built an e-commerce recommendation engine with Java, improving user purchase rates by 18%.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resume_4 = \"\"\"\n",
    "Skills: Python, R, SQL, Machine Learning, Deep Learning, Pandas, Scikit-learn, TensorFlow, Data Visualization, NLP\n",
    "\n",
    "Experience:\n",
    "- Built predictive models using machine learning algorithms to forecast sales, achieving 90% accuracy.\n",
    "- Conducted data analysis for customer segmentation, resulting in a 15% increase in marketing efficiency.\n",
    "- Created dashboards and visualizations in Tableau to present insights to stakeholders.\n",
    "\n",
    "Education: Master’s in Data Science, Stanford University\n",
    "\n",
    "Projects:\n",
    "- Developed a sentiment analysis tool using NLP to analyze customer feedback.\n",
    "- Created a recommendation system for a streaming service using collaborative filtering.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resume_5 = \"\"\"\n",
    "Skills: Cybersecurity, Network Security, Ethical Hacking, Incident Response, Threat Analysis, Risk Assessment, Firewalls, IDS/IPS, Malware Analysis, Encryption, Forensics\n",
    "\n",
    "Experience:\n",
    "- Conducted vulnerability assessments and penetration testing, identifying and mitigating security risks in network systems.\n",
    "- Managed incident response for security breaches, reducing downtime by 40%.\n",
    "- Developed and implemented security policies and protocols, resulting in improved security posture and compliance.\n",
    "\n",
    "Education: Bachelor’s in Cybersecurity, University of Texas\n",
    "\n",
    "Projects:\n",
    "- Built a tool to automate log analysis and identify suspicious activity patterns for enhanced threat detection.\n",
    "- Led a team to design a secure network architecture for a financial institution, minimizing risk of cyber attacks.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Data Science: 65.69%\n",
      "Python Developer: 34.31%\n",
      "Other: 0.00%\n",
      "Database: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "DotNet Developer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "DotNet Developer: 100.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Java Developer: 0.00%\n",
      "Other: 0.00%\n",
      "Data Science: 0.00%\n",
      "Database: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Java Developer: 100.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Other: 0.00%\n",
      "Database: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Data Science: 0.00%\n",
      "Testing: 0.00%\n",
      "DotNet Developer: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Data Science: 100.00%\n",
      "Other: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Database: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "DotNet Developer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Other: 100.00%\n",
      "Database: 0.00%\n",
      "Data Science: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "Testing: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "DotNet Developer: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_parser_mac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
