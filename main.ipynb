{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "final_df = pd.read_csv('data/UpdatedResumeDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ashraf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you have your simplified dataset loaded as final_df with 'Category' and 'Resume' columns\n",
    "\n",
    "# Download stopwords if not already done\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Define a comprehensive function to clean resume text\n",
    "def clean_resume(resume_text):\n",
    "    # Remove URLs, RT, cc, hashtags, mentions, and extra whitespace\n",
    "    resume_text = re.sub('http\\S+\\s*', ' ', resume_text)\n",
    "    resume_text = re.sub('RT|cc', ' ', resume_text)\n",
    "    resume_text = re.sub('#\\S+', '', resume_text)\n",
    "    resume_text = re.sub('@\\S+', ' ', resume_text)\n",
    "    resume_text = re.sub(r'[^\\x00-\\x7f]', ' ', resume_text)\n",
    "    resume_text = re.sub('\\s+', ' ', resume_text)\n",
    "    \n",
    "    # Remove punctuation and non-alphabet characters\n",
    "    resume_text = re.sub('[%s]' % re.escape(string.punctuation), ' ', resume_text)\n",
    "    resume_text = re.sub(r'[^a-zA-Z\\s]', '', resume_text)\n",
    "\n",
    "    # Split into words and remove stop words, months, years\n",
    "    words = resume_text.split()\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words \n",
    "             and word.lower() not in [\"year\", \"years\", \"month\", \"months\"]\n",
    "             and not word.isdigit()]\n",
    "    \n",
    "    # Join cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function\n",
    "final_df['Resume'] = final_df['Resume'].apply(clean_resume)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "final_df['Category'] = label_encoder.fit_transform(final_df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(final_df['Resume'])\n",
    "y = final_df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9792746113989638\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      0.50      0.67         4\n",
      "                     Arts       0.88      1.00      0.93         7\n",
      "       Automation Testing       1.00      0.80      0.89         5\n",
      "               Blockchain       1.00      1.00      1.00         8\n",
      "         Business Analyst       0.86      1.00      0.92         6\n",
      "           Civil Engineer       1.00      1.00      1.00         5\n",
      "             Data Science       1.00      1.00      1.00         8\n",
      "                 Database       1.00      1.00      1.00         7\n",
      "          DevOps Engineer       1.00      0.91      0.95        11\n",
      "         DotNet Developer       1.00      1.00      1.00         5\n",
      "            ETL Developer       1.00      1.00      1.00         8\n",
      "   Electrical Engineering       0.86      1.00      0.92         6\n",
      "                       HR       1.00      1.00      1.00         9\n",
      "                   Hadoop       1.00      1.00      1.00         8\n",
      "       Health and fitness       1.00      1.00      1.00         6\n",
      "           Java Developer       1.00      1.00      1.00        17\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "Network Security Engineer       1.00      1.00      1.00         5\n",
      "       Operations Manager       1.00      1.00      1.00         8\n",
      "                      PMO       1.00      1.00      1.00         6\n",
      "         Python Developer       1.00      1.00      1.00        10\n",
      "            SAP Developer       1.00      1.00      1.00         5\n",
      "                    Sales       0.89      1.00      0.94         8\n",
      "                  Testing       1.00      1.00      1.00        14\n",
      "            Web Designing       1.00      1.00      1.00         9\n",
      "\n",
      "                 accuracy                           0.98       193\n",
      "                macro avg       0.98      0.97      0.97       193\n",
      "             weighted avg       0.98      0.98      0.98       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the model\n",
    "model = OneVsRestClassifier(MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the specific categories to display; others will be grouped under \"Other\"\n",
    "\n",
    "def predication_func(new_resume):\n",
    "\n",
    "    display_categories = [\n",
    "    \"Data Science\", \n",
    "    \"Database\", \n",
    "    \"DevOps Engineer\", \n",
    "    \"DotNet Developer\", \n",
    "    \"Java Developer\", \n",
    "    \"Python Developer\", \n",
    "    \"Testing\", \n",
    "    \"Web Designing\"\n",
    "    ]   \n",
    "    cleaned_resume = clean_resume(new_resume)\n",
    "\n",
    "    # Vectorize the cleaned resume using the same vectorizer\n",
    "    new_resume_vec = vectorizer.transform([cleaned_resume])\n",
    "\n",
    "    # Generate category probabilities\n",
    "    category_probs = model.predict_proba(new_resume_vec)\n",
    "\n",
    "    # Get category names instead of numeric labels\n",
    "    category_names = label_encoder.inverse_transform(model.classes_)\n",
    "\n",
    "    # Group the categories and calculate probabilities for \"Other\"\n",
    "    category_percentage = {}\n",
    "    other_total = 0  # To accumulate percentages for categories marked as \"Other\"\n",
    "\n",
    "    for i, prob in enumerate(category_probs[0]):\n",
    "        category_name = category_names[i]\n",
    "        if category_name in display_categories:\n",
    "            category_percentage[category_name] = prob * 100\n",
    "        else:\n",
    "            other_total += prob * 100\n",
    "\n",
    "    # Add \"Other\" category if there are remaining categories\n",
    "    if other_total > 0:\n",
    "        category_percentage[\"Other\"] = other_total\n",
    "\n",
    "    # # Display match percentages for each category\n",
    "    # print(\"Match percentages for each category:\")\n",
    "    # for category, percent in category_percentage.items():\n",
    "    #     print(f\"{category}: {percent:.2f}%\")\n",
    "\n",
    "    # Sort and display top matches\n",
    "    sorted_matches = sorted(category_percentage.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop category matches:\")\n",
    "    for category, percent in sorted_matches:\n",
    "        print(f\"{category}: {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resume_1 = \"\"\"\n",
    "Skills: Python, Django, Flask, REST APIs, SQL, NoSQL, Git, Docker, AWS, Data Analysis, Pandas, NumPy\n",
    "\n",
    "Experience:\n",
    "- Developed RESTful APIs using Django and Flask for an e-commerce platform, reducing load times by 20%.\n",
    "- Built automated scripts for data cleaning and ETL processes using Python and Pandas, saving 15 hours of manual work weekly.\n",
    "- Integrated third-party services with OAuth and JWT authentication for secure data handling.\n",
    "\n",
    "Education: Bachelor’s in Computer Science, University of California\n",
    "\n",
    "Projects:\n",
    "- Built a chatbot using Natural Language Processing techniques for customer support.\n",
    "- Developed a web scraping tool using Python and BeautifulSoup to extract and analyze online reviews.\n",
    "\"\"\"\n",
    "\n",
    "resume_2 = \"\"\"\n",
    "Skills: C#, .NET Core, ASP.NET MVC, Entity Framework, LINQ, SQL Server, Azure, Agile, Git, REST APIs\n",
    "\n",
    "Experience:\n",
    "- Designed and implemented web applications using ASP.NET MVC and .NET Core, increasing user engagement by 30%.\n",
    "- Worked with Azure DevOps to deploy and manage cloud-based applications.\n",
    "- Used Entity Framework to create and maintain database connections and ensure data integrity.\n",
    "\n",
    "Education: Bachelor’s in Information Technology, University of Texas\n",
    "\n",
    "Projects:\n",
    "- Developed a ticket booking system with ASP.NET Core and Entity Framework.\n",
    "- Created a performance monitoring tool for web apps to enhance response times by 25%.\n",
    "\"\"\"\n",
    "\n",
    "resume_3 = \"\"\"\n",
    "Skills: Java, Spring Boot, Hibernate, SQL, Microservices, Maven, Git, RESTful APIs, Jenkins, AWS\n",
    "\n",
    "Experience:\n",
    "- Built scalable microservices with Spring Boot, handling over 1 million requests per day.\n",
    "- Designed a notification system using Java and RabbitMQ, improving alert delivery efficiency by 40%.\n",
    "- Collaborated with cross-functional teams on Java-based applications for e-commerce platforms.\n",
    "\n",
    "Education: Bachelor’s in Software Engineering, University of Michigan\n",
    "\n",
    "Projects:\n",
    "- Developed a library management system using Java and Hibernate.\n",
    "- Built an e-commerce recommendation engine with Java, improving user purchase rates by 18%.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resume_4 = \"\"\"\n",
    "Skills: Python, R, SQL, Machine Learning, Deep Learning, Pandas, Scikit-learn, TensorFlow, Data Visualization, NLP\n",
    "\n",
    "Experience:\n",
    "- Built predictive models using machine learning algorithms to forecast sales, achieving 90% accuracy.\n",
    "- Conducted data analysis for customer segmentation, resulting in a 15% increase in marketing efficiency.\n",
    "- Created dashboards and visualizations in Tableau to present insights to stakeholders.\n",
    "\n",
    "Education: Master’s in Data Science, Stanford University\n",
    "\n",
    "Projects:\n",
    "- Developed a sentiment analysis tool using NLP to analyze customer feedback.\n",
    "- Created a recommendation system for a streaming service using collaborative filtering.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resume_5 = \"\"\"\n",
    "Skills: Cybersecurity, Network Security, Ethical Hacking, Incident Response, Threat Analysis, Risk Assessment, Firewalls, IDS/IPS, Malware Analysis, Encryption, Forensics\n",
    "\n",
    "Experience:\n",
    "- Conducted vulnerability assessments and penetration testing, identifying and mitigating security risks in network systems.\n",
    "- Managed incident response for security breaches, reducing downtime by 40%.\n",
    "- Developed and implemented security policies and protocols, resulting in improved security posture and compliance.\n",
    "\n",
    "Education: Bachelor’s in Cybersecurity, University of Texas\n",
    "\n",
    "Projects:\n",
    "- Built a tool to automate log analysis and identify suspicious activity patterns for enhanced threat detection.\n",
    "- Led a team to design a secure network architecture for a financial institution, minimizing risk of cyber attacks.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Data Science: 65.69%\n",
      "Python Developer: 34.31%\n",
      "Other: 0.00%\n",
      "Database: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "DotNet Developer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "DotNet Developer: 100.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Java Developer: 0.00%\n",
      "Other: 0.00%\n",
      "Data Science: 0.00%\n",
      "Database: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Java Developer: 100.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Other: 0.00%\n",
      "Database: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Data Science: 0.00%\n",
      "Testing: 0.00%\n",
      "DotNet Developer: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Data Science: 100.00%\n",
      "Other: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Database: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "DotNet Developer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "Testing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top category matches:\n",
      "Other: 100.00%\n",
      "Database: 0.00%\n",
      "Data Science: 0.00%\n",
      "Python Developer: 0.00%\n",
      "Java Developer: 0.00%\n",
      "Testing: 0.00%\n",
      "DevOps Engineer: 0.00%\n",
      "Web Designing: 0.00%\n",
      "DotNet Developer: 0.00%\n"
     ]
    }
   ],
   "source": [
    "predication_func(resume_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_parser_mac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
